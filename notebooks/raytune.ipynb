{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tempfile\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from filelock import FileLock\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=10, top_k=1)\n",
    "        self.layer_1_size = config[\"layer_1_size\"]\n",
    "        self.layer_2_size = config[\"layer_2_size\"]\n",
    "        self.lr = config[\"lr\"]\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
    "        self.layer_1 = torch.nn.Linear(28 * 28, self.layer_1_size)\n",
    "        self.layer_2 = torch.nn.Linear(self.layer_1_size, self.layer_2_size)\n",
    "        self.layer_3 = torch.nn.Linear(self.layer_2_size, 10)\n",
    "        self.eval_loss = []\n",
    "        self.eval_accuracy = []\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.nll_loss(logits, labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height = x.size()\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        x = self.layer_1(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.layer_2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.layer_3(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        accuracy = self.accuracy(logits, y)\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        self.log(\"ptl/train_accuracy\", accuracy)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        accuracy = self.accuracy(logits, y)\n",
    "        self.eval_loss.append(loss)\n",
    "        self.eval_accuracy.append(accuracy)\n",
    "        return {\"val_loss\": loss, \"val_accuracy\": accuracy}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.eval_loss).mean()\n",
    "        avg_acc = torch.stack(self.eval_accuracy).mean()\n",
    "        self.log(\"ptl/val_loss\", avg_loss, sync_dist=True)\n",
    "        self.log(\"ptl/val_accuracy\", avg_acc, sync_dist=True)\n",
    "        self.eval_loss.clear()\n",
    "        self.eval_accuracy.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.data_dir = tempfile.mkdtemp()\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        )\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        with FileLock(f\"{self.data_dir}.lock\"):\n",
    "            mnist = MNIST(\n",
    "                self.data_dir, train=True, download=True, transform=self.transform\n",
    "            )\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist, [55000, 5000])\n",
    "\n",
    "            self.mnist_test = MNIST(\n",
    "                self.data_dir, train=False, download=True, transform=self.transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "    \"layer_1_size\": 128,\n",
    "    \"layer_2_size\": 256,\n",
    "    \"lr\": 1e-3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.lightning import (\n",
    "    RayDDPStrategy,\n",
    "    RayLightningEnvironment,\n",
    "    RayTrainReportCallback,\n",
    "    prepare_trainer,\n",
    ")\n",
    "\n",
    "\n",
    "def train_func(config):\n",
    "    dm = MNISTDataModule(batch_size=config[\"batch_size\"])\n",
    "    model = MNISTClassifier(config)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        devices=\"auto\",\n",
    "        accelerator=\"auto\",\n",
    "        strategy=RayDDPStrategy(),\n",
    "        callbacks=[RayTrainReportCallback()],\n",
    "        plugins=[RayLightningEnvironment()],\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer = prepare_trainer(trainer)\n",
    "    trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"layer_1_size\": tune.choice([32, 64, 128]),\n",
    "    \"layer_2_size\": tune.choice([64, 128, 256]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([32, 64]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Number of sampls from parameter space\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=3, use_gpu=True, resources_per_worker={\"CPU\": 1, \"GPU\": 0}\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        num_to_keep=2,\n",
    "        checkpoint_score_attribute=\"ptl/val_accuracy\",\n",
    "        checkpoint_score_order=\"max\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "# Define a TorchTrainer without hyper-parameters for Tuner\n",
    "ray_trainer = TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-28 17:35:10</td></tr>\n",
       "<tr><td>Running for: </td><td>00:14:51.07        </td></tr>\n",
       "<tr><td>Memory:      </td><td>4.9/15.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 0/4 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   train_loop_config/ba\n",
       "tch_size</th><th style=\"text-align: right;\">    train_loop_config/la\n",
       "yer_1_size</th><th style=\"text-align: right;\">    train_loop_config/la\n",
       "yer_2_size</th><th style=\"text-align: right;\">  train_loop_config/lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_0334c_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">64</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">           0.00331451 </td></tr>\n",
       "<tr><td>TorchTrainer_0334c_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">64</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">           0.002094   </td></tr>\n",
       "<tr><td>TorchTrainer_0334c_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">           0.000175745</td></tr>\n",
       "<tr><td>TorchTrainer_0334c_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">           0.0559725  </td></tr>\n",
       "<tr><td>TorchTrainer_0334c_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">           0.0980119  </td></tr>\n",
       "<tr><td>TorchTrainer_0334c_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">           0.00592966 </td></tr>\n",
       "<tr><td>TorchTrainer_0334c_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">64</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">           0.00157499 </td></tr>\n",
       "<tr><td>TorchTrainer_0334c_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">           0.000116221</td></tr>\n",
       "<tr><td>TorchTrainer_0334c_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">           0.000275549</td></tr>\n",
       "<tr><td>TorchTrainer_0334c_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">           0.0727857  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +49s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[33m(autoscaler +49s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +49s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +1m24s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +1m24s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:21:19,876\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1m59s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +1m59s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +2m34s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +2m34s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:22:19,975\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +3m9s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +3m9s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +3m45s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +3m45s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:23:19,979\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +4m20s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +4m20s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:24:20,072\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +4m55s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +4m55s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +5m30s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +5m30s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:25:20,165\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +6m5s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +6m5s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +6m40s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +6m40s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:26:20,262\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +7m15s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +7m15s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:27:20,360\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +7m50s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +7m50s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +8m25s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +8m25s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:28:20,460\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +9m0s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +9m0s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +9m35s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +9m35s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:29:20,548\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +10m10s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +10m10s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +10m45s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +10m45s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:30:20,644\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +11m20s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +11m20s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:31:20,732\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +11m55s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +11m55s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +12m30s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +12m30s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:32:20,830\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +13m6s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +13m6s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +13m41s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +13m41s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:33:20,929\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +14m16s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +14m16s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 17:34:21,026\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 3.0 GPUs per trial, but the cluster only has 4.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +14m51s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +14m51s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +15m26s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[33m(autoscaler +15m26s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    }
   ],
   "source": [
    "def tune_mnist_asha(num_samples=10):\n",
    "    scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        ray_trainer,\n",
    "        param_space={\"train_loop_config\": search_space},\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"ptl/val_accuracy\",\n",
    "            mode=\"max\",\n",
    "            num_samples=num_samples,\n",
    "            scheduler=scheduler,\n",
    "        ),\n",
    "    )\n",
    "    return tuner.fit()\n",
    "\n",
    "\n",
    "results = tune_mnist_asha(num_samples=num_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
